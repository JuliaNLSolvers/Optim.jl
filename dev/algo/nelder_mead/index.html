<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Nelder Mead · Optim</title><meta name="title" content="Nelder Mead · Optim"/><meta property="og:title" content="Nelder Mead · Optim"/><meta property="twitter:title" content="Nelder Mead · Optim"/><meta name="description" content="Documentation for Optim."/><meta property="og:description" content="Documentation for Optim."/><meta property="twitter:description" content="Documentation for Optim."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Optim</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../user/minimization/">Minimizing a function</a></li><li><a class="tocitem" href="../../user/gradientsandhessians/">Gradients and Hessians</a></li><li><a class="tocitem" href="../../user/config/">Configurable Options</a></li><li><a class="tocitem" href="../linesearch/">Linesearch</a></li><li><a class="tocitem" href="../../user/algochoice/">Algorithm choice</a></li><li><a class="tocitem" href="../precondition/">Preconditioners</a></li><li><a class="tocitem" href="../complex/">Complex optimization</a></li><li><a class="tocitem" href="../manifolds/">Manifolds</a></li><li><a class="tocitem" href="../../user/tipsandtricks/">Tips and tricks</a></li><li><a class="tocitem" href="../../examples/generated/ipnewton_basics/">Interior point Newton</a></li><li><a class="tocitem" href="../../examples/generated/maxlikenlm/">Maximum likelihood estimation</a></li><li><a class="tocitem" href="../../examples/generated/rasch/">Conditional maximum likelihood estimation</a></li></ul></li><li><span class="tocitem">Algorithms</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox" checked/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">Gradient Free</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>Nelder Mead</a><ul class="internal"><li><a class="tocitem" href="#Constructor"><span>Constructor</span></a></li><li><a class="tocitem" href="#Description"><span>Description</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../simulated_annealing/">Simulated Annealing</a></li><li><a class="tocitem" href="../samin/">Simulated Annealing w/ bounds</a></li><li><a class="tocitem" href="../particle_swarm/">Particle Swarm</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Gradient Required</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../adam_adamax/">Adam and AdaMax</a></li><li><a class="tocitem" href="../cg/">Conjugate Gradient</a></li><li><a class="tocitem" href="../gradientdescent/">Gradient Descent</a></li><li><a class="tocitem" href="../lbfgs/">(L-)BFGS</a></li><li><a class="tocitem" href="../ngmres/">Acceleration</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Hessian Required</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../newton/">Newton</a></li><li><a class="tocitem" href="../newton_trust_region/">Newton with Trust Region</a></li><li><a class="tocitem" href="../ipnewton/">Interior point Newton</a></li></ul></li></ul></li><li><a class="tocitem" href="../../dev/contributing/">Contributing</a></li><li><a class="tocitem" href="../../LICENSE/">License</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Algorithms</a></li><li><a class="is-disabled">Gradient Free</a></li><li class="is-active"><a href>Nelder Mead</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Nelder Mead</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaNLSolvers/Optim.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaNLSolvers/Optim.jl/blob/master/docs/src/algo/nelder_mead.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Nelder-Mead"><a class="docs-heading-anchor" href="#Nelder-Mead">Nelder-Mead</a><a id="Nelder-Mead-1"></a><a class="docs-heading-anchor-permalink" href="#Nelder-Mead" title="Permalink"></a></h1><p>Nelder-Mead is currently the standard algorithm when no derivatives are provided.</p><h2 id="Constructor"><a class="docs-heading-anchor" href="#Constructor">Constructor</a><a id="Constructor-1"></a><a class="docs-heading-anchor-permalink" href="#Constructor" title="Permalink"></a></h2><pre><code class="language-julia hljs">NelderMead(; parameters = AdaptiveParameters(),
             initial_simplex = AffineSimplexer())</code></pre><p>The keywords in the constructor are used to control the following parts of the solver:</p><ul><li><code>parameters</code> is a an instance of either <code>AdaptiveParameters</code> or <code>FixedParameters</code>, and is used to generate parameters for the Nelder-Mead Algorithm.</li><li><code>initial_simplex</code> is an instance of <code>AffineSimplexer</code>. See more details below.</li></ul><h2 id="Description"><a class="docs-heading-anchor" href="#Description">Description</a><a id="Description-1"></a><a class="docs-heading-anchor-permalink" href="#Description" title="Permalink"></a></h2><p>Our current implementation of the Nelder-Mead algorithm is based on Nelder and Mead (1965) and Gao and Han (2010). Gradient free methods can be a bit sensitive to starting values and tuning parameters, so it is a good idea to be careful with the defaults provided in Optim.</p><p>Instead of using gradient information, Nelder-Mead is a direct search method. It keeps track of the function value at a number of points in the search space. Together, the points form a simplex. Given a simplex, we can perform one of four actions: reflect, expand, contract, or shrink. Basically, the goal is to iteratively replace the worst point with a better point. More information can be found in Nelder and Mead (1965), Lagarias, et al (1998) or Gao and Han (2010).</p><p>The stopping rule is the same as in the original paper, and is the standard error of the function values at the vertices. To set the tolerance level for this convergence criterion, set the <code>g_tol</code> level as described in the Configurable Options section.</p><p>When the solver finishes, we return a minimizer which is either the centroid or one of the vertices. The function value at the centroid adds a function evaluation, as we need to evaluate the objection at the centroid to choose the smallest function value. However, even if the function value at the centroid can be returned as the minimum, we do not trace it during the optimization iterations. This is to avoid too many evaluations of the objective function which can be computationally expensive. Typically, there should be no more than twice as many <code>f_calls</code> than <code>iterations</code>.  Adding an evaluation at the centroid when tracing could considerably increase the total run-time of the algorithm.</p><h3 id="Specifying-the-initial-simplex"><a class="docs-heading-anchor" href="#Specifying-the-initial-simplex">Specifying the initial simplex</a><a id="Specifying-the-initial-simplex-1"></a><a class="docs-heading-anchor-permalink" href="#Specifying-the-initial-simplex" title="Permalink"></a></h3><p>The default choice of <code>initial_simplex</code> is <code>AffineSimplexer()</code>. A simplex is represented by an <span>$(n+1)$</span>-dimensional vector of <span>$n$</span>-dimensional vectors. It is used together  with the initial <code>x</code> to create the initial simplex. To construct the <span>$i$</span>th vertex, it simply multiplies entry <span>$i$</span> in the initial vector with a constant <code>b</code>, and adds a constant <code>a</code>. This means that the <span>$i$</span>th of the <span>$n$</span> additional vertices is of the form</p><p class="math-container">\[(x_0^1, x_0^2, \ldots, x_0^i, \ldots, 0,0) + (0, 0, \ldots, x_0^i\cdot b+a,\ldots, 0,0)\]</p><p>If an <span>$x_0^i$</span> is zero, we need the <span>$a$</span> to make sure all vertices are unique. Generally, it is advised to start with a relatively large simplex.</p><p>If a specific simplex is wanted, it is possible to construct the <span>$(n+1)$</span>-vector of <span>$n$</span>-dimensional vectors, and pass it to the solver using a new type definition and a new method for the function <code>simplexer</code>. For example, let us minimize the two-dimensional Rosenbrock function, and choose three vertices that have elements that are simply standard uniform draws.</p><pre><code class="language-julia hljs">using Optim
struct MySimplexer &lt;: Optim.Simplexer end
Optim.simplexer(S::MySimplexer, initial_x) = [rand(length(initial_x)) for i = 1:length(initial_x)+1]
f(x) = (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2
optimize(f, [.0, .0], NelderMead(initial_simplex = MySimplexer()))</code></pre><p>Say we want to implement the initial simplex as in Matlab&#39;s <code>fminsearch</code>. This is very close to the <code>AffineSimplexer</code> above, but with a small twist. Instead of always adding the <code>a</code>, a constant is only added to entries that are zero. If the entry is non-zero, five percent of the level is added. This might be implemented (by the user) as</p><pre><code class="language-julia hljs">struct MatlabSimplexer{T} &lt;: Optim.Simplexer
    a::T
    b::T
end
MatlabSimplexer(;a = 0.00025, b = 0.05) = MatlabSimplexer(a, b)

function Optim.simplexer(S::MatlabSimplexer, initial_x::AbstractArray{T, N}) where {T, N}
    n = length(initial_x)
    initial_simplex = Array{T, N}[copy(initial_x) for i = 1:n+1]
    for j = 1:n
        initial_simplex[j+1][j] += initial_simplex[j+1][j] != zero(T) ? S.b * initial_simplex[j+1][j] : S.a
    end
    initial_simplex
end</code></pre><h3 id="The-parameters-of-Nelder-Mead"><a class="docs-heading-anchor" href="#The-parameters-of-Nelder-Mead">The parameters of Nelder-Mead</a><a id="The-parameters-of-Nelder-Mead-1"></a><a class="docs-heading-anchor-permalink" href="#The-parameters-of-Nelder-Mead" title="Permalink"></a></h3><p>The different types of steps in the algorithm are governed by four parameters: <span>$\alpha$</span> for the reflection, <span>$\beta$</span> for the expansion, <span>$\gamma$</span> for the contraction, and <span>$\delta$</span> for the shrink step. We default to the adaptive parameters scheme in Gao and Han (2010). These are based on the dimensionality of the problem, and are given by</p><p class="math-container">\[\alpha = 1, \quad \beta = 1+2/n,\quad \gamma =0.75 - 1/2n,\quad \delta = 1-1/n\]</p><p>It is also possible to specify the original parameters from Nelder and Mead (1965)</p><p class="math-container">\[\alpha = 1,\quad \beta = 2, \quad\gamma = 1/2, \quad\delta = 1/2\]</p><p>by specifying <code>parameters  = Optim.FixedParameters()</code>. For specifying custom values, <code>parameters  = Optim.FixedParameters(α = a, β = b, γ = g, δ = d)</code> is used, where a, b, g, d are the chosen values. If another parameter specification is wanted, it is possible to create a custom sub-type of<code>Optim.NMParameters</code>, and add a method to the <code>parameters</code> function. It should take the new type as the first positional argument, and the dimensionality of <code>x</code> as the second positional argument, and return a 4-tuple of parameters. However, it will often be easier to simply supply the wanted parameters to <code>FixedParameters</code>.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><div class="citation canonical"><ul><li><div id="gao2012">Gao, F. and Han, L. (2012). <em>Implementing the Nelder-Mead Simplex Algorithm with Adaptive Parameters</em>. <a href="https://doi.org/10.1007/s10589-010-9329-3">Computational Optimization and Applications <strong>51</strong>, 259–277</a>.</div></li><li><div id="lagarias1998">Lagarias, J. C.; Reeds, J. A.; Wright, M. H. and Wright, P. E. (1998). <em>Convergence Properties of the Nelder–Mead Simplex Method in Low Dimensions</em>. <a href="https://doi.org/10.1137/S1052623496303470">SIAM Journal on Optimization <strong>9</strong>, 112–147</a>.</div></li><li><div id="nelder1965">Nelder, J. A. and Mead, R. (1965). <em>A Simplex Method for Function Minimization</em>. <a href="https://doi.org/10.1093/comjnl/7.4.308">The Computer Journal <strong>7</strong>, 308–313</a>.</div></li></ul></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../examples/generated/rasch/">« Conditional maximum likelihood estimation</a><a class="docs-footer-nextpage" href="../simulated_annealing/">Simulated Annealing »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.12.0 on <span class="colophon-date" title="Thursday 12 June 2025 09:50">Thursday 12 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
