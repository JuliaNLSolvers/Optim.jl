<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Complex optimization · Optim</title><meta name="title" content="Complex optimization · Optim"/><meta property="og:title" content="Complex optimization · Optim"/><meta property="twitter:title" content="Complex optimization · Optim"/><meta name="description" content="Documentation for Optim."/><meta property="og:description" content="Documentation for Optim."/><meta property="twitter:description" content="Documentation for Optim."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Optim</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../user/minimization/">Minimizing a function</a></li><li><a class="tocitem" href="../../user/gradientsandhessians/">Gradients and Hessians</a></li><li><a class="tocitem" href="../../user/config/">Configurable Options</a></li><li><a class="tocitem" href="../linesearch/">Linesearch</a></li><li><a class="tocitem" href="../../user/algochoice/">Algorithm choice</a></li><li><a class="tocitem" href="../precondition/">Preconditioners</a></li><li class="is-active"><a class="tocitem" href>Complex optimization</a><ul class="internal"><li><a class="tocitem" href="#Examples"><span>Examples</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../manifolds/">Manifolds</a></li><li><a class="tocitem" href="../../user/tipsandtricks/">Tips and tricks</a></li><li><a class="tocitem" href="../../examples/generated/ipnewton_basics/">Interior point Newton</a></li><li><a class="tocitem" href="../../examples/generated/maxlikenlm/">Maximum likelihood estimation</a></li><li><a class="tocitem" href="../../examples/generated/rasch/">Conditional maximum likelihood estimation</a></li></ul></li><li><span class="tocitem">Algorithms</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox"/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">Gradient Free</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../nelder_mead/">Nelder Mead</a></li><li><a class="tocitem" href="../simulated_annealing/">Simulated Annealing</a></li><li><a class="tocitem" href="../samin/">Simulated Annealing w/ bounds</a></li><li><a class="tocitem" href="../particle_swarm/">Particle Swarm</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Gradient Required</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../cg/">Conjugate Gradient</a></li><li><a class="tocitem" href="../gradientdescent/">Gradient Descent</a></li><li><a class="tocitem" href="../lbfgs/">(L-)BFGS</a></li><li><a class="tocitem" href="../ngmres/">Acceleration</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Hessian Required</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../newton/">Newton</a></li><li><a class="tocitem" href="../newton_trust_region/">Newton with Trust Region</a></li><li><a class="tocitem" href="../ipnewton/">Interior point Newton</a></li></ul></li></ul></li><li><a class="tocitem" href="../../dev/contributing/">Contributing</a></li><li><a class="tocitem" href="../../LICENSE/">License</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Complex optimization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Complex optimization</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaNLSolvers/Optim.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaNLSolvers/Optim.jl/blob/master/docs/src/algo/complex.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Complex-optimization"><a class="docs-heading-anchor" href="#Complex-optimization">Complex optimization</a><a id="Complex-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Complex-optimization" title="Permalink"></a></h1><p>Optimization of functions defined on complex inputs (<span>$\mathbb{C}^n \to \mathbb{R}$</span>) is supported by simply passing a complex <span>$x$</span> as input. The algorithms supported are all those which can naturally be extended to work with complex numbers: simulated annealing and all the first-order methods.</p><p>The gradient of a complex-to-real function is defined as the only vector <span>$g$</span> such that</p><p class="math-container">\[f(x+h) = f(x) + \mbox{Re}(g&#39; * h) + \mathcal{O}(h^2).\]</p><p>This is sometimes written</p><p class="math-container">\[g = \frac{df}{d(z*)} = \frac{df}{d(\mbox{Re}(z))} + i \frac{df}{d(\mbox{Im(z)})}.\]</p><p>The gradient of a <span>$\mathbb{C}^n \to \mathbb{R}$</span> function is a <span>$\mathbb{C}^n \to \mathbb{C}^n$</span> map. Even if it is differentiable when seen as a function of <span>$\mathbb{R}^{2n}$</span> to <span>$\mathbb{R}^{2n}$</span>, it might not be complex-differentiable. For instance, take <span>$f(z) = \mbox{Re}(z)^2$</span>. Then <span>$g(z) = 2 \mbox{Re}(z)$</span>, which is not complex-differentiable (holomorphic). Therefore, the Hessian of a <span>$\mathbb{C}^n \to \mathbb{R}$</span> function is in general not well-defined as a <span>$n \times n$</span> complex matrix (only as a <span>$2n \times 2n$</span> real matrix), and therefore second-order optimization algorithms are not applicable directly. To use second-order optimization, convert to real variables.</p><h2 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h2><p>We show how to minimize a quadratic plus quartic function with the <code>LBFGS</code> optimization algorithm.</p><pre><code class="language-jl hljs">using Random
Random.seed!(0) # Set the seed for reproducibility
# μ is the strength of the quartic. μ = 0 is just a quadratic problem
n = 4
A = randn(n,n) + im*randn(n,n)
A = A&#39;A + I
b = randn(n) + im*randn(n)
μ = 1.0

fcomplex(x) = real(dot(x,A*x)/2 - dot(b,x)) + μ*sum(abs.(x).^4)
gcomplex(x) = A*x-b + 4μ*(abs.(x).^2).*x
gcomplex!(stor,x) = copyto!(stor,gcomplex(x))

x0 = randn(n)+im*randn(n)

res = optimize(fcomplex, gcomplex!, x0, LBFGS())</code></pre><p>The output of the optimization is</p><pre><code class="nohighlight hljs">Results of Optimization Algorithm
 * Algorithm: L-BFGS
 * Starting Point: [0.48155603952425174 - 1.477880724921868im,-0.3219431528959694 - 0.18542418173298963im, ...]
 * Minimizer: [0.14163543901272568 - 0.034929496785515886im,-0.1208600058040362 - 0.6125620908171383im, ...]
 * Minimum: -1.568997e+00
 * Iterations: 16
 * Convergence: true
   * |x - x&#39;| ≤ 0.0e+00: false
     |x - x&#39;| = 3.28e-09
   * |f(x) - f(x&#39;)| ≤ 0.0e+00 |f(x)|: false
     |f(x) - f(x&#39;)| = -4.25e-16 |f(x)|
   * |g(x)| ≤ 1.0e-08: true
     |g(x)| = 6.33e-11
   * Stopped by an increasing objective: false
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 48
 * Gradient Calls: 48</code></pre><p>Similarly, with <code>ConjugateGradient</code>.</p><pre><code class="language-julia hljs">res = optimize(fcomplex, gcomplex!, x0, ConjugateGradient())</code></pre><pre><code class="nohighlight hljs">Results of Optimization Algorithm
 * Algorithm: Conjugate Gradient
 * Starting Point: [0.48155603952425174 - 1.477880724921868im,-0.3219431528959694 - 0.18542418173298963im, ...]
 * Minimizer: [0.1416354378490425 - 0.034929499492595516im,-0.12086000949769983 - 0.6125620892675705im, ...]
 * Minimum: -1.568997e+00
 * Iterations: 23
 * Convergence: false
   * |x - x&#39;| ≤ 0.0e+00: false
     |x - x&#39;| = 8.54e-10
   * |f(x) - f(x&#39;)| ≤ 0.0e+00 |f(x)|: false
     |f(x) - f(x&#39;)| = -4.25e-16 |f(x)|
   * |g(x)| ≤ 1.0e-08: false
     |g(x)| = 3.72e-08
   * Stopped by an increasing objective: true
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 51
 * Gradient Calls: 29</code></pre><h3 id="Differentation"><a class="docs-heading-anchor" href="#Differentation">Differentation</a><a id="Differentation-1"></a><a class="docs-heading-anchor-permalink" href="#Differentation" title="Permalink"></a></h3><p>The finite difference methods used by <code>Optim</code> support real functions with complex inputs.</p><pre><code class="language-julia hljs">res = optimize(fcomplex, x0, LBFGS())</code></pre><pre><code class="nohighlight hljs">Results of Optimization Algorithm
 * Algorithm: L-BFGS
 * Starting Point: [0.48155603952425174 - 1.477880724921868im,-0.3219431528959694 - 0.18542418173298963im, ...]
 * Minimizer: [0.1416354390108624 - 0.034929496786122484im,-0.12086000580073922 - 0.6125620908025359im, ...]
 * Minimum: -1.568997e+00
 * Iterations: 16
 * Convergence: true
   * |x - x&#39;| ≤ 0.0e+00: false
     |x - x&#39;| = 3.28e-09
   * |f(x) - f(x&#39;)| ≤ 0.0e+00 |f(x)|: true
     |f(x) - f(x&#39;)| = 0.00e+00 |f(x)|
   * |g(x)| ≤ 1.0e-08: true
     |g(x)| = 1.04e-10
   * Stopped by an increasing objective: false
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 48
 * Gradient Calls: 48</code></pre><p>Automatic differentiation support for complex inputs may come when <a href="https://github.com/JuliaDiff/Capstan.jl">Cassete.jl</a> is ready.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ul><li>Sorber, L., Barel, M. V., &amp; Lathauwer, L. D. (2012). Unconstrained optimization of real functions in complex variables. SIAM Journal on Optimization, 22(3), 879-898.</li><li>Kreutz-Delgado, K. (2009). The complex gradient operator and the CR-calculus. arXiv preprint arXiv:0906.4835.</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../precondition/">« Preconditioners</a><a class="docs-footer-nextpage" href="../manifolds/">Manifolds »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Friday 26 January 2024 10:08">Friday 26 January 2024</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
