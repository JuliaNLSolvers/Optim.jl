<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Newton&#39;s Method · Optim</title><meta name="title" content="Newton&#39;s Method · Optim"/><meta property="og:title" content="Newton&#39;s Method · Optim"/><meta property="twitter:title" content="Newton&#39;s Method · Optim"/><meta name="description" content="Documentation for Optim."/><meta property="og:description" content="Documentation for Optim."/><meta property="twitter:description" content="Documentation for Optim."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Optim</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Optim.jl</a></li><li><a class="tocitem" href="../../LICENSE/">-</a></li><li><a class="tocitem" href="../">Solvers</a></li><li><a class="tocitem" href="../brent/">Brent&#39;s Method</a></li><li><a class="tocitem" href="../cg/">Conjugate Gradient Descent</a></li><li><a class="tocitem" href="../complex/">Complex optimization</a></li><li><a class="tocitem" href="../goldensection/">Golden Section</a></li><li><a class="tocitem" href="../gradientdescent/">Gradient Descent</a></li><li><a class="tocitem" href="../ipnewton/">Interior point Newton method</a></li><li><a class="tocitem" href="../lbfgs/">(L-)BFGS</a></li><li><a class="tocitem" href="../linesearch/">Line search</a></li><li><a class="tocitem" href="../manifolds/">Manifold optimization</a></li><li><a class="tocitem" href="../nelder_mead/">Nelder-Mead</a></li><li class="is-active"><a class="tocitem" href>Newton&#39;s Method</a><ul class="internal"><li><a class="tocitem" href="#Constructor"><span>Constructor</span></a></li><li><a class="tocitem" href="#Description"><span>Description</span></a></li><li><a class="tocitem" href="#Example"><span>Example</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../newton_trust_region/">Newton&#39;s Method With a Trust Region</a></li><li><a class="tocitem" href="../ngmres/">Acceleration methods: N-GMRES and O-ACCEL</a></li><li><a class="tocitem" href="../particle_swarm/">Particle Swarm</a></li><li><a class="tocitem" href="../precondition/">Preconditioning</a></li><li><a class="tocitem" href="../samin/">SAMIN</a></li><li><a class="tocitem" href="../simulated_annealing/">Simulated Annealing</a></li><li><a class="tocitem" href="../../dev/">-</a></li><li><a class="tocitem" href="../../dev/contributing/">-</a></li><li><a class="tocitem" href="../../examples/generated/ipnewton_basics/">Nonlinear constrained optimization</a></li><li><a class="tocitem" href="../../examples/generated/maxlikenlm/">Maximum Likelihood Estimation: The Normal Linear Model</a></li><li><a class="tocitem" href="../../examples/generated/rasch/">Conditional Maximum Likelihood for the Rasch Model</a></li><li><a class="tocitem" href="../../user/algochoice/">-</a></li><li><a class="tocitem" href="../../user/config/">-</a></li><li><a class="tocitem" href="../../user/gradientsandhessians/">-</a></li><li><a class="tocitem" href="../../user/minimization/">-</a></li><li><a class="tocitem" href="../../user/tipsandtricks/">-</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Newton&#39;s Method</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Newton&#39;s Method</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaNLSolvers/Optim.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaNLSolvers/Optim.jl/blob/master/docs/src/algo/newton.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Newton&#39;s-Method"><a class="docs-heading-anchor" href="#Newton&#39;s-Method">Newton&#39;s Method</a><a id="Newton&#39;s-Method-1"></a><a class="docs-heading-anchor-permalink" href="#Newton&#39;s-Method" title="Permalink"></a></h1><h2 id="Constructor"><a class="docs-heading-anchor" href="#Constructor">Constructor</a><a id="Constructor-1"></a><a class="docs-heading-anchor-permalink" href="#Constructor" title="Permalink"></a></h2><pre><code class="language-julia hljs">Newton(; alphaguess = LineSearches.InitialStatic(),
         linesearch = LineSearches.HagerZhang())</code></pre><p>The constructor takes two keywords:</p><ul><li><code>linesearch = a(d, x, p, x_new, g_new, phi0, dphi0, c)</code>, a function performing line search, see the line search section.</li><li><code>alphaguess = a(state, dphi0, d)</code>, a function for setting the initial guess for the line search algorithm, see the line search section.</li></ul><h2 id="Description"><a class="docs-heading-anchor" href="#Description">Description</a><a id="Description-1"></a><a class="docs-heading-anchor-permalink" href="#Description" title="Permalink"></a></h2><p>Newton&#39;s method for optimization has a long history, and is in some sense the gold standard in unconstrained optimization of smooth functions, at least from a theoretical viewpoint. The main benefit is that it has a quadratic rate of convergence near a local optimum. The main disadvantage is that the user has to provide a Hessian. This can be difficult, complicated, or simply annoying. It can also be computationally expensive to calculate it.</p><p>Newton&#39;s method for optimization consists of applying Newton&#39;s method for solving systems of equations, where the equations are the first order conditions, saying that the gradient should equal the zero vector.</p><p class="math-container">\[\nabla f(x) = 0\]</p><p>A second order Taylor expansion of the left-hand side leads to the iterative scheme</p><p class="math-container">\[x_{n+1} = x_n - H(x_n)^{-1}\nabla f(x_n)\]</p><p>where the inverse is not calculated directly, but the step size is instead calculated by solving</p><p class="math-container">\[H(x) \textbf{s} = \nabla f(x_n).\]</p><p>This is equivalent to minimizing a quadratic model, <span>$m_k$</span> around the current <span>$x_n$</span></p><p class="math-container">\[m_k(s) = f(x_n) + \nabla f(x_n)^\top \textbf{s} + \frac{1}{2} \textbf{s}^\top H(x_n) \textbf{s}\]</p><p>For functions where <span>$H(x_n)$</span> is difficult, or computationally expensive to obtain, we might replace the Hessian with another positive definite matrix that approximates it. Such methods are called Quasi-Newton methods; see (L-)BFGS and Gradient Descent.</p><p>In a sufficiently small neighborhood around the minimizer, Newton&#39;s method has quadratic convergence, but globally it might have slower convergence, or it might even diverge. To ensure convergence, a line search is performed for each <span>$\textbf{s}$</span>. This amounts to replacing the step formula above with</p><p class="math-container">\[x_{n+1} = x_n - \alpha \textbf{s}\]</p><p>and finding a scalar <span>$\alpha$</span> such that we get sufficient descent; see the line search section for more information.</p><p>Additionally, if the function is locally concave, the step taken in the formulas above will go in a direction of ascent,  as the Hessian will not be positive (semi)definite. To avoid this, we use a specialized method to calculate the step direction. If the Hessian is positive semidefinite then the method used is standard, but if it is not, a correction is made using the functionality in <a href="https://github.com/timholy/PositiveFactorizations.jl">PositiveFactorizations.jl</a>.</p><h2 id="Example"><a class="docs-heading-anchor" href="#Example">Example</a><a id="Example-1"></a><a class="docs-heading-anchor-permalink" href="#Example" title="Permalink"></a></h2><p>show the example from the issue</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../nelder_mead/">« Nelder-Mead</a><a class="docs-footer-nextpage" href="../newton_trust_region/">Newton&#39;s Method With a Trust Region »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Thursday 25 January 2024 12:03">Thursday 25 January 2024</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
