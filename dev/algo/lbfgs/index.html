<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>(L-)BFGS · Optim</title><meta name="title" content="(L-)BFGS · Optim"/><meta property="og:title" content="(L-)BFGS · Optim"/><meta property="twitter:title" content="(L-)BFGS · Optim"/><meta name="description" content="Documentation for Optim."/><meta property="og:description" content="Documentation for Optim."/><meta property="twitter:description" content="Documentation for Optim."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Optim</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../user/minimization/">Minimizing a function</a></li><li><a class="tocitem" href="../../user/gradientsandhessians/">Gradients and Hessians</a></li><li><a class="tocitem" href="../../user/config/">Configurable Options</a></li><li><a class="tocitem" href="../linesearch/">Linesearch</a></li><li><a class="tocitem" href="../../user/algochoice/">Algorithm choice</a></li><li><a class="tocitem" href="../precondition/">Preconditioners</a></li><li><a class="tocitem" href="../complex/">Complex optimization</a></li><li><a class="tocitem" href="../manifolds/">Manifolds</a></li><li><a class="tocitem" href="../../user/tipsandtricks/">Tips and tricks</a></li><li><a class="tocitem" href="../../examples/generated/ipnewton_basics/">Interior point Newton</a></li><li><a class="tocitem" href="../../examples/generated/maxlikenlm/">Maximum likelihood estimation</a></li><li><a class="tocitem" href="../../examples/generated/rasch/">Conditional maximum likelihood estimation</a></li></ul></li><li><span class="tocitem">Algorithms</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox"/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">Gradient Free</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../nelder_mead/">Nelder Mead</a></li><li><a class="tocitem" href="../simulated_annealing/">Simulated Annealing</a></li><li><a class="tocitem" href="../samin/">Simulated Annealing w/ bounds</a></li><li><a class="tocitem" href="../particle_swarm/">Particle Swarm</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox" checked/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Gradient Required</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../adam_adamax/">Adam and AdaMax</a></li><li><a class="tocitem" href="../cg/">Conjugate Gradient</a></li><li><a class="tocitem" href="../gradientdescent/">Gradient Descent</a></li><li class="is-active"><a class="tocitem" href>(L-)BFGS</a><ul class="internal"><li><a class="tocitem" href="#Constructors"><span>Constructors</span></a></li><li><a class="tocitem" href="#Description"><span>Description</span></a></li><li><a class="tocitem" href="#Example"><span>Example</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../ngmres/">Acceleration</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Hessian Required</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../newton/">Newton</a></li><li><a class="tocitem" href="../newton_trust_region/">Newton with Trust Region</a></li><li><a class="tocitem" href="../ipnewton/">Interior point Newton</a></li></ul></li></ul></li><li><a class="tocitem" href="../../dev/contributing/">Contributing</a></li><li><a class="tocitem" href="../../LICENSE/">License</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Algorithms</a></li><li><a class="is-disabled">Gradient Required</a></li><li class="is-active"><a href>(L-)BFGS</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>(L-)BFGS</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaNLSolvers/Optim.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaNLSolvers/Optim.jl/blob/master/docs/src/algo/lbfgs.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="(L-)BFGS"><a class="docs-heading-anchor" href="#(L-)BFGS">(L-)BFGS</a><a id="(L-)BFGS-1"></a><a class="docs-heading-anchor-permalink" href="#(L-)BFGS" title="Permalink"></a></h1><p>This page contains information about BFGS and its limited memory version L-BFGS.</p><h2 id="Constructors"><a class="docs-heading-anchor" href="#Constructors">Constructors</a><a id="Constructors-1"></a><a class="docs-heading-anchor-permalink" href="#Constructors" title="Permalink"></a></h2><pre><code class="language-julia hljs">BFGS(; alphaguess = LineSearches.InitialStatic(),
       linesearch = LineSearches.HagerZhang(),
       initial_invH = nothing,
       initial_stepnorm = nothing,
       manifold = Flat())</code></pre><p><code>initial_invH</code> has a default value of <code>nothing</code>. If the user has a specific initial matrix they want to supply, it should be supplied as a function of an array similar to the initial point <code>x0</code>.</p><p>If <code>initial_stepnorm</code> is set to a number <code>z</code>, the initial matrix will be the identity matrix scaled by <code>z</code> times the sup-norm of the gradient at the initial point <code>x0</code>.</p><pre><code class="language-julia hljs">LBFGS(; m = 10,
        alphaguess = LineSearches.InitialStatic(),
        linesearch = LineSearches.HagerZhang(),
        P = nothing,
        precondprep = (P, x) -&gt; nothing,
        manifold = Flat(),
        scaleinvH0::Bool = true &amp;&amp; (typeof(P) &lt;: Nothing))</code></pre><h2 id="Description"><a class="docs-heading-anchor" href="#Description">Description</a><a id="Description-1"></a><a class="docs-heading-anchor-permalink" href="#Description" title="Permalink"></a></h2><p>This means that it takes steps according to</p><p class="math-container">\[x_{n+1} = x_n - P^{-1}\nabla f(x_n)\]</p><p>where <span>$P$</span> is a positive definite matrix. If <span>$P$</span> is the Hessian, we get Newton&#39;s method. In (L-)BFGS, the matrix is an approximation to the Hessian built using differences in the gradient across iterations. As long as the initial matrix is positive definite  it is possible to show that all the follow matrices will be as well. The starting matrix could simply be the identity matrix, such that the first step is identical to the Gradient Descent algorithm, or even the actual Hessian.</p><p>There are two versions of BFGS in the package: BFGS, and L-BFGS. The latter is different from the former because it doesn&#39;t use a complete history of the iterative procedure to construct <span>$P$</span>, but rather only the latest <span>$m$</span> steps. It doesn&#39;t actually build the Hessian approximation matrix either, but computes the direction directly. This makes more suitable for large scale problems, as the memory requirement to store the relevant vectors will grow quickly in large problems.</p><p>As with the other quasi-Newton solvers in this package, a scalar <span>$\alpha$</span> is introduced as follows</p><p class="math-container">\[x_{n+1} = x_n - \alpha P^{-1}\nabla f(x_n)\]</p><p>and is chosen by a linesearch algorithm such that each step gives sufficient descent.</p><h2 id="Example"><a class="docs-heading-anchor" href="#Example">Example</a><a id="Example-1"></a><a class="docs-heading-anchor-permalink" href="#Example" title="Permalink"></a></h2><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><p>Wright, Stephen, and Jorge Nocedal (2006) &quot;Numerical optimization.&quot; Springer</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gradientdescent/">« Gradient Descent</a><a class="docs-footer-nextpage" href="../ngmres/">Acceleration »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.0 on <span class="colophon-date" title="Monday 29 April 2024 20:37">Monday 29 April 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
