<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Algorithm choice · Optim</title><meta name="title" content="Algorithm choice · Optim"/><meta property="og:title" content="Algorithm choice · Optim"/><meta property="twitter:title" content="Algorithm choice · Optim"/><meta name="description" content="Documentation for Optim."/><meta property="og:description" content="Documentation for Optim."/><meta property="twitter:description" content="Documentation for Optim."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Optim</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../minimization/">Minimizing a function</a></li><li><a class="tocitem" href="../gradientsandhessians/">Gradients and Hessians</a></li><li><a class="tocitem" href="../config/">Configurable Options</a></li><li><a class="tocitem" href="../../algo/linesearch/">Linesearch</a></li><li class="is-active"><a class="tocitem" href>Algorithm choice</a><ul class="internal"><li><a class="tocitem" href="#Algorithm-choice"><span>Algorithm choice</span></a></li><li><a class="tocitem" href="#Algorithms"><span>Algorithms</span></a></li><li><a class="tocitem" href="#Linesearches"><span>Linesearches</span></a></li><li><a class="tocitem" href="#Summary"><span>Summary</span></a></li></ul></li><li><a class="tocitem" href="../../algo/precondition/">Preconditioners</a></li><li><a class="tocitem" href="../../algo/complex/">Complex optimization</a></li><li><a class="tocitem" href="../../algo/manifolds/">Manifolds</a></li><li><a class="tocitem" href="../tipsandtricks/">Tips and tricks</a></li><li><a class="tocitem" href="../../examples/generated/ipnewton_basics/">Interior point Newton</a></li><li><a class="tocitem" href="../../examples/generated/maxlikenlm/">Maximum likelihood estimation</a></li><li><a class="tocitem" href="../../examples/generated/rasch/">Conditional maximum likelihood estimation</a></li></ul></li><li><span class="tocitem">Algorithms</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox"/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">Gradient Free</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../algo/nelder_mead/">Nelder Mead</a></li><li><a class="tocitem" href="../../algo/simulated_annealing/">Simulated Annealing</a></li><li><a class="tocitem" href="../../algo/samin/">Simulated Annealing w/ bounds</a></li><li><a class="tocitem" href="../../algo/particle_swarm/">Particle Swarm</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Gradient Required</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../algo/adam_adamax/">Adam and AdaMax</a></li><li><a class="tocitem" href="../../algo/cg/">Conjugate Gradient</a></li><li><a class="tocitem" href="../../algo/gradientdescent/">Gradient Descent</a></li><li><a class="tocitem" href="../../algo/lbfgs/">(L-)BFGS</a></li><li><a class="tocitem" href="../../algo/ngmres/">Acceleration</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Hessian Required</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../algo/newton/">Newton</a></li><li><a class="tocitem" href="../../algo/newton_trust_region/">Newton with Trust Region</a></li><li><a class="tocitem" href="../../algo/ipnewton/">Interior point Newton</a></li></ul></li></ul></li><li><a class="tocitem" href="../../dev/contributing/">Contributing</a></li><li><a class="tocitem" href="../../LICENSE/">License</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Algorithm choice</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Algorithm choice</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaNLSolvers/Optim.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaNLSolvers/Optim.jl/blob/master/docs/src/user/algochoice.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h2 id="Algorithm-choice"><a class="docs-heading-anchor" href="#Algorithm-choice">Algorithm choice</a><a id="Algorithm-choice-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithm-choice" title="Permalink"></a></h2><p>There are two main settings you must choose in Optim: the algorithm and the linesearch.</p><h2 id="Algorithms"><a class="docs-heading-anchor" href="#Algorithms">Algorithms</a><a id="Algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithms" title="Permalink"></a></h2><p>The first choice to be made is that of the order of the method. Zeroth-order methods do not have gradient information, and are very slow to converge, especially in high dimension. First-order methods do not have access to curvature information and can take a large number of iterations to converge for badly conditioned problems. Second-order methods can converge very quickly once in the vicinity of a minimizer. Of course, this enhanced performance comes at a cost: the objective function has to be differentiable, you have to supply gradients and Hessians, and, for second order methods, a linear system has to be solved at each step.</p><p>If you can provide analytic gradients and Hessians, and the dimension of the problem is not too large, then second order methods are very efficient. The Newton method with trust region is the method of choice.</p><p>When you do not have an explicit Hessian or when the dimension becomes large enough that the linear solve in the Newton method becomes the bottleneck, first order methods should be preferred. BFGS is a very efficient method, but also requires a linear system solve. LBFGS usually has a performance very close to that of BFGS, and avoids linear system solves (the parameter <code>m</code> can be tweaked: increasing it can improve the convergence, at the expense of memory and time spent in linear algebra operations). The conjugate gradient method usually converges less quickly than LBFGS, but requires less memory. Gradient descent should only be used for testing. Acceleration methods are experimental.</p><p>When the objective function is non-differentiable or you do not want to use gradients, use zeroth-order methods. Nelder-Mead is currently the most robust.</p><h2 id="Linesearches"><a class="docs-heading-anchor" href="#Linesearches">Linesearches</a><a id="Linesearches-1"></a><a class="docs-heading-anchor-permalink" href="#Linesearches" title="Permalink"></a></h2><p>Linesearches are used in every first- and second-order method except for the trust-region Newton method. Linesearch routines attempt to locate quickly an approximate minimizer of the univariate function <span>$\alpha \to f(x+ \alpha d)$</span>, where <span>$d$</span> is the descent direction computed by the algorithm. They vary in how accurate this minimization is. Two good linesearches are BackTracking and HagerZhang, the former being less stringent than the latter. For well-conditioned objective functions and methods where the step is usually well-scaled (such as LBFGS or Newton), a rough linesearch such as BackTracking is usually the most performant. For badly behaved problems or when extreme accuracy is needed (gradients below the square root of the machine epsilon, about <span>$10^{-8}$</span> with <code>Float64</code>), the HagerZhang method proves more robust. An exception is the conjugate gradient method which requires an accurate linesearch to be efficient, and should be used with the HagerZhang linesearch.</p><h2 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h2><p>As a very crude heuristic:</p><p>For a low-dimensional problem with analytic gradients and Hessians, use the Newton method with trust region. For larger problems or when there is no analytic Hessian, use LBFGS, and tweak the parameter <code>m</code> if needed. If the function is non-differentiable, use Nelder-Mead. Use the HagerZhang linesearch for robustness and BackTracking for speed.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../algo/linesearch/">« Linesearch</a><a class="docs-footer-nextpage" href="../../algo/precondition/">Preconditioners »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Tuesday 12 November 2024 12:39">Tuesday 12 November 2024</span>. Using Julia version 1.11.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
