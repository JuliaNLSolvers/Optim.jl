<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Configurable Options · Optim</title><meta name="title" content="Configurable Options · Optim"/><meta property="og:title" content="Configurable Options · Optim"/><meta property="twitter:title" content="Configurable Options · Optim"/><meta name="description" content="Documentation for Optim."/><meta property="og:description" content="Documentation for Optim."/><meta property="twitter:description" content="Documentation for Optim."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Optim</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../minimization/">Minimizing a function</a></li><li><a class="tocitem" href="../gradientsandhessians/">Gradients and Hessians</a></li><li class="is-active"><a class="tocitem" href>Configurable Options</a><ul class="internal"><li><a class="tocitem" href="#Configurable-options"><span>Configurable options</span></a></li></ul></li><li><a class="tocitem" href="../../algo/linesearch/">Linesearch</a></li><li><a class="tocitem" href="../algochoice/">Algorithm choice</a></li><li><a class="tocitem" href="../../algo/precondition/">Preconditioners</a></li><li><a class="tocitem" href="../../algo/complex/">Complex optimization</a></li><li><a class="tocitem" href="../../algo/manifolds/">Manifolds</a></li><li><a class="tocitem" href="../tipsandtricks/">Tips and tricks</a></li><li><a class="tocitem" href="../../examples/generated/ipnewton_basics/">Interior point Newton</a></li><li><a class="tocitem" href="../../examples/generated/maxlikenlm/">Maximum likelihood estimation</a></li><li><a class="tocitem" href="../../examples/generated/rasch/">Conditional maximum likelihood estimation</a></li></ul></li><li><span class="tocitem">Algorithms</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox"/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">Gradient Free</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../algo/nelder_mead/">Nelder Mead</a></li><li><a class="tocitem" href="../../algo/simulated_annealing/">Simulated Annealing</a></li><li><a class="tocitem" href="../../algo/samin/">Simulated Annealing w/ bounds</a></li><li><a class="tocitem" href="../../algo/particle_swarm/">Particle Swarm</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Gradient Required</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../algo/adam_adamax/">Adam and AdaMax</a></li><li><a class="tocitem" href="../../algo/cg/">Conjugate Gradient</a></li><li><a class="tocitem" href="../../algo/gradientdescent/">Gradient Descent</a></li><li><a class="tocitem" href="../../algo/lbfgs/">(L-)BFGS</a></li><li><a class="tocitem" href="../../algo/ngmres/">Acceleration</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Hessian Required</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../algo/newton/">Newton</a></li><li><a class="tocitem" href="../../algo/newton_trust_region/">Newton with Trust Region</a></li><li><a class="tocitem" href="../../algo/ipnewton/">Interior point Newton</a></li></ul></li></ul></li><li><a class="tocitem" href="../../dev/contributing/">Contributing</a></li><li><a class="tocitem" href="../../LICENSE/">License</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Configurable Options</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Configurable Options</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaNLSolvers/Optim.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaNLSolvers/Optim.jl/blob/master/docs/src/user/config.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h2 id="Configurable-options"><a class="docs-heading-anchor" href="#Configurable-options">Configurable options</a><a id="Configurable-options-1"></a><a class="docs-heading-anchor-permalink" href="#Configurable-options" title="Permalink"></a></h2><p>There are several options that simply take on some default values if the user doesn&#39;t supply anything else than a function (and gradient) and a starting point.</p><h3 id="Solver-options"><a class="docs-heading-anchor" href="#Solver-options">Solver options</a><a id="Solver-options-1"></a><a class="docs-heading-anchor-permalink" href="#Solver-options" title="Permalink"></a></h3><p>There quite a few different solvers available in Optim, and they are all listed below. Notice that the constructors are written without input here, but they generally take keywords to tweak the way they work. See the pages describing each solver for more detail.</p><p>Requires only a function handle:</p><ul><li><code>NelderMead()</code></li><li><code>SimulatedAnnealing()</code></li></ul><p>Requires a function and gradient (will be approximated if omitted):</p><ul><li><code>BFGS()</code></li><li><code>LBFGS()</code></li><li><code>ConjugateGradient()</code></li><li><code>GradientDescent()</code></li><li><code>MomentumGradientDescent()</code></li><li><code>AcceleratedGradientDescent()</code></li></ul><p>Requires a function, a gradient, and a Hessian (cannot be omitted):</p><ul><li><code>Newton()</code></li><li><code>NewtonTrustRegion()</code></li></ul><p>Box constrained minimization:</p><ul><li><code>Fminbox()</code></li></ul><p>Special methods for bounded univariate optimization:</p><ul><li><code>Brent()</code></li><li><code>GoldenSection()</code></li></ul><h3 id="General-Options"><a class="docs-heading-anchor" href="#General-Options">General Options</a><a id="General-Options-1"></a><a class="docs-heading-anchor-permalink" href="#General-Options" title="Permalink"></a></h3><p>In addition to the solver, you can alter the behavior of the Optim package by using the following keywords:</p><ul><li><code>x_tol</code>: Absolute tolerance in changes of the input vector <code>x</code>, in infinity norm. Defaults to <code>0.0</code>.</li><li><code>f_tol</code>: Relative tolerance in changes of the objective value. Defaults to <code>0.0</code>.</li><li><code>g_tol</code>: Absolute tolerance in the gradient, in infinity norm. Defaults to <code>1e-8</code>. For gradient free methods, this will control the main convergence tolerance, which is solver specific.</li><li><code>f_calls_limit</code>: A soft upper limit on the number of objective calls. Defaults to <code>0</code> (unlimited).</li><li><code>g_calls_limit</code>: A soft upper limit on the number of gradient calls. Defaults to <code>0</code> (unlimited).</li><li><code>h_calls_limit</code>: A soft upper limit on the number of Hessian calls. Defaults to <code>0</code> (unlimited).</li><li><code>allow_f_increases</code>: Allow steps that increase the objective value. Defaults to <code>false</code>. Note that, when setting this to <code>true</code>, the last iterate will be returned as the minimizer even if the objective increased.</li><li><code>iterations</code>: How many iterations will run before the algorithm gives up? Defaults to <code>1_000</code>.</li><li><code>store_trace</code>: Should a trace of the optimization algorithm&#39;s state be stored? Defaults to <code>false</code>.</li><li><code>show_trace</code>: Should a trace of the optimization algorithm&#39;s state be shown on <code>stdout</code>? Defaults to <code>false</code>.</li><li><code>extended_trace</code>: Save additional information. Solver dependent. Defaults to <code>false</code>.</li><li><code>show_warnings</code>: Should warnings due to NaNs or Inf be shown? Defaults to <code>true</code>.</li><li><code>trace_simplex</code>: Include the full simplex in the trace for <code>NelderMead</code>. Defaults to <code>false</code>.</li><li><code>show_every</code>: Trace output is printed every <code>show_every</code>th iteration.</li><li><code>callback</code>: A function to be called during tracing. A return value of <code>true</code> stops the <code>optimize</code> call. The callback function is called every <code>show_every</code>th iteration. If <code>store_trace</code> is false, the argument to the callback is of the type  <a href="https://github.com/JuliaNLSolvers/Optim.jl/blob/a1035134ca1f3ebe855f1cde034e32683178225a/src/types.jl#L155"><code>OptimizationState</code></a>, describing the state of the current iteration. If <code>store_trace</code> is true, the argument is a list of all the states from the first iteration to the current. </li><li><code>time_limit</code>: A soft upper limit on the total run time. Defaults to <code>NaN</code> (unlimited).</li></ul><p>Box constrained optimization has additional keywords to alter the behavior of the outer solver:</p><ul><li><code>outer_x_tol</code>: Absolute tolerance in changes of the input vector <code>x</code>, in infinity norm. Defaults to <code>0.0</code>.</li><li><code>outer_f_tol</code>: Relative tolerance in changes of the objective value. Defaults to <code>0.0</code>.</li><li><code>outer_g_tol</code>: Absolute tolerance in the gradient, in infinity norm. Defaults to <code>1e-8</code>. For gradient free methods, this will control the main convergence tolerance, which is solver specific.</li><li><code>allow_outer_f_increases</code>: Allow steps that increase the objective value. Defaults to <code>false</code>. Note that, when setting this to <code>true</code>, the last iterate will be returned as the minimizer even if the objective increased.</li><li><code>outer_iterations</code>: How many iterations will run before the algorithm gives up? Defaults to <code>1_000</code>.</li></ul><p>If you specify <code>outer_iterations = 10</code> and <code>iterations = 100</code>, the outer algorithm will run for <code>10</code> iterations, and for each outer iteration the inner algorithm will run for <code>100</code> iterations.</p><p>We currently recommend the statically dispatched interface by using the <code>Optim.Options</code> constructor:</p><pre><code class="language-jl hljs">res = optimize(f, g!,
               [0.0, 0.0],
               GradientDescent(),
               Optim.Options(g_tol = 1e-12,
                             iterations = 10,
                             store_trace = true,
                             show_trace = false,
                             show_warnings = true))</code></pre><p>Another interface is also available, based directly on keywords:</p><pre><code class="language-jl hljs">res = optimize(f, g!,
               [0.0, 0.0],
               method = GradientDescent(),
               g_tol = 1e-12,
               iterations = 10,
               store_trace = true,
               show_trace = false,
               show_warnings = true)</code></pre><p>Notice the need to specify the method using a keyword if this syntax is used. This approach might be deprecated in the future, and as a result we recommend writing code that has to maintained using the <code>Optim.Options</code> approach.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gradientsandhessians/">« Gradients and Hessians</a><a class="docs-footer-nextpage" href="../../algo/linesearch/">Linesearch »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Saturday 23 March 2024 00:50">Saturday 23 March 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
